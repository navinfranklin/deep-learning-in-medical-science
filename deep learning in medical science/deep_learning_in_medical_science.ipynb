{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep learning clg proj7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNxZ6NkEaPKr",
        "outputId": "9df6faf3-6c73-46f7-aeaa-b3b5feb233ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqlM98rkrOco"
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aML599xdrXh6"
      },
      "source": [
        "# resize the images\n",
        "IMAGE_SIZE = [224, 224]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y0LjQrdrsGi"
      },
      "source": [
        "#importing dataset\n",
        "train_path = '/content/drive/My Drive/train'\n",
        "valid_path = '/content/drive/My Drive/test'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JNQuPoosBRb"
      },
      "source": [
        "#creating preprocessing layer to the front of VGG we use 3 for rgb imagenet is used for classifing 1000 and more \n",
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZcf6le7tdPR"
      },
      "source": [
        "# we should not train existing weights as we are the weights with imagenet\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODLjK9DYuU2s"
      },
      "source": [
        " # as we have 2 folder as our train we need to findout the classes for that it will be useful for getting number of classes\n",
        "folders = glob('/content/drive/My Drive/train/*')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfOzg_K9u_-n"
      },
      "source": [
        "# for the layers we can increase the amout of layers as we want we have to flatten what we have got in vvgoutput\n",
        "x = Flatten()(vgg.output)\n",
        "# we use the lenght of the folders instead of giving the values as 1000 or somthing else\n",
        "prediction = Dense(len(folders), activation='softmax')(x)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbW__Tn8xqqo"
      },
      "source": [
        "# now we have to create a model\n",
        "model = Model(inputs=vgg.input, outputs=prediction)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REYSRWvjx0TF",
        "outputId": "e3c0222d-a5f6-43b1-9847-de0186aabd3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "# view the structure or summary  of the model we use this\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 50178     \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 50,178\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkEGzoAPynXZ"
      },
      "source": [
        "#from this summary we can understand that last dense is 2 layer output as we have 2 folders like normal and pneumonia inside test and as well as train \n",
        "#and we will have 16 layers as we have used vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBxLzvPpyq0C"
      },
      "source": [
        "# now assigning the cost and optimizer for the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8irVXvszTKt"
      },
      "source": [
        "# now by using the imagedatagenerator we need to make the images from both the folders rescale,shearrange,zoom range to make the images equal\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOINAw7m0VgV",
        "outputId": "3e081c34-4585-4357-e794-79f4fd853eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#now we need to choose the directory for the train and test and fix the class mode as categorical we can also use binary as we have only 2 categories\n",
        "#it will retrive all the images present in both normal and pneumonia folder and gives as a output\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Cz2QXp2Vlo",
        "outputId": "3079afcb-5be1-4f0e-85a4-3a3b2f963137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# now fitting the model as we dont have a great GPU make the epoch small for less timing \n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=5,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "163/163 [==============================] - 2853s 18s/step - loss: 0.1797 - accuracy: 0.9245 - val_loss: 0.2455 - val_accuracy: 0.9119\n",
            "Epoch 2/5\n",
            "163/163 [==============================] - 116s 713ms/step - loss: 0.1108 - accuracy: 0.9555 - val_loss: 0.5138 - val_accuracy: 0.8526\n",
            "Epoch 3/5\n",
            "163/163 [==============================] - 116s 711ms/step - loss: 0.0924 - accuracy: 0.9641 - val_loss: 0.3266 - val_accuracy: 0.9022\n",
            "Epoch 4/5\n",
            "163/163 [==============================] - 116s 713ms/step - loss: 0.0942 - accuracy: 0.9651 - val_loss: 0.3310 - val_accuracy: 0.8990\n",
            "Epoch 5/5\n",
            "163/163 [==============================] - 116s 713ms/step - loss: 0.0734 - accuracy: 0.9722 - val_loss: 0.2676 - val_accuracy: 0.9151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFFbzreuEs_p"
      },
      "source": [
        "# it took 2 hrs 15 mins for 5 epoch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_3hNXoyE8pJ",
        "outputId": "0cc3be0f-4108-4dbb-990e-f2c3391ea549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# ploting the loss function \n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOg3T8ZlGruo"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "model.save('model_vgg19.h5')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRgpAofeH0rb"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "model = load_model('model_vgg19.h5')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXCG4AHeH6oQ"
      },
      "source": [
        "#now predict the images without the disease\n",
        "#after getting the image we have to convert it into the array after that we have to expand the dimension so that we can be able to use all the images\n",
        "img = image.load_img('/content/drive/My Drive/val/NORMAL/NORMAL2-IM-1427-0001.jpeg', target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "img_data = preprocess_input(x)\n",
        "classes = model.predict(img_data)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvFSFvtbJIJS"
      },
      "source": [
        "# from the above i have used the normal image from the test data to check whether it is affected with pneumonia or not by predicting we get to now that array 0 is the not affected part and array 1 is affected part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QReEc30ISFn",
        "outputId": "0fd68491-1a17-4550-a6f5-3037ed63b42e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classes"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000000e+00, 1.1053389e-28]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "838uOH4kId7e"
      },
      "source": [
        "#now predict the images with the disease\n",
        "img = image.load_img('/content/drive/My Drive/val/PNEUMONIA/person1946_bacteria_4874.jpeg', target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "img_data = preprocess_input(x)\n",
        "classes1 = model.predict(img_data)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOC0dZFsIlIj",
        "outputId": "10a93cef-af05-4c04-90d3-5b60679b02e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classes1"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaZwyC7pLzYW"
      },
      "source": [
        "#here we get to know that the pperson is affected as we got zero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6mmvWYtJGUp"
      },
      "source": [
        ""
      ]
    }
  ]
}